# ğŸš€ Getting Started with elevata

> The practical guide to setting up your elevata metadata environment  
> â€” from installation to first successful metadata import.

---

## ğŸ§© 1. Prerequisites

Before you start, make sure the following are available:

| Requirement | Recommended Version | Notes |
|--------------|---------------------|--------|
| **Python**   | 3.11                | Required for full feature support |
| **PostgreSQL** | 14+               | Used as elevata metadata repository (SQLite works fine for local use) |
| **Git**      | any recent version  | For cloning and version control |

Optional but helpful:  
- **DuckDB** for quick SQL preview and rendering tests  
- **Docker Compose** for local all-in-one setup in case you want PostgreSQL instead of SQLite  

> *Frontend dependencies are handled directly by Django; no separate Node.js build is required.*

---

## âš™ï¸ 2. Environment Setup

First clone the repo  

```bash
git clone https://github.com/elevata-labs/elevata.git
cd elevata
```

Create and activate a virtual environment:

```bash
python -m venv .venv
source .venv/bin/activate   # on Linux / macOS
.venv\Scripts\activate      # on Windows
```

Install dependencies:

```bash
pip install -r requirements/base.txt
```

Copy the example environment configuration and adjust it:

```bash
cp .env.example .env
```
Edit `.env` according to your local setup, e.g.:

```bash
# Choose which metadata database type you want
DB_ENGINE=sqlite # or postgres

# Pepper value for deterministic surrogate keys
SEC_DEV_PEPPER=supersecretpeppervalue
```
---

## ğŸ—ï¸ 3. Initialize the Metadata Database

### ğŸ›¢ï¸ Option SQLite (recommended for first-time setup)

If you just want to explore elevata or run metadata generation locally,  
you donâ€™t need PostgreSQL â€” SQLite works out of the box.

Just make sure your `.env` contains:

```bash
DB_ENGINE=sqlite
``` 

Then run the standard migrations:

```bash
python manage.py migrate
python manage.py createsuperuser
```

This will create a local file `db.sqlite3` in your project root.  
Perfect for demos, prototyping, or CI pipelines.

### ğŸ›¢ï¸ Option PostgreSQL (for shared or production environments)

If you prefer PostgreSQL for shared or production use, install postgres extras:

```bash
pip install -r requirements/postgres.txt
```

Alternative 1: run postgres (17) locally with docker:

```bash
docker compose -f core/postgres/docker-compose.yml up -d db
```

Alternative 2: Use your own PostgreSQL (no Docker):  
If you already have a PostgreSQL server (managed or self-hosted), configure elevata to use it:  
Configure connection via discrete DB_* variables in your .env file.  
Ensure role & database exist (if you need to create them):

```bash
create role elevata login password 'elevata';
create database elevata owner elevata;
```

Then run the standard migrations:

```bash
python manage.py migrate
python manage.py createsuperuser
```

---

## ğŸ§® 4. Explore the Metadata UI

Start the development server:
```bash
python manage.py runserver
```
Then open [http://localhost:8000](http://localhost:8000) and log in with your superuser credentials.

You can now:
- Trigger **auto-import of source system metadata**
- Inspect **source datasets and columns**
- Define **integration rules** (`integrate = True`)
- Trigger **target auto-generation**
- Preview **auto-generated** SQL renderings (starting with DuckDB dialect)

---

## ğŸ”‘ 5. Secure Connectivity (optional)

If youâ€™re connecting to production metadata systems,
use environment variables instead of plain-text passwords.

For advanced setups, see  
â¡ï¸ [`secure_metadata_connectivity.md`](secure_metadata_connectivity.md)

---

## ğŸ§° 6. Useful Commands

| Purpose | Command |
|----------|---------|
| Run development server | `python manage.py runserver` |
| Open Django shell | `python manage.py shell` |
| Import source metadata | Trigger via UI (âš¡ Import Datasets) |
| Generate target structures | Trigger via UI (âš¡ Generate Targets) |
| Run tests | `pytest` |

---

## ğŸ§­ Next Steps

Once your metadata environment is ready, continue with:

- [Automatic Target Generation Logic](generation_logic.md)
- [SQL Rendering & Alias Conventions](sql_rendering_conventions.md)
- [Lineage Model & Logical Plan](logical_plan.md)

---

Â© 2025 elevata Labs â€” Internal Technical Documentation