# âš™ï¸ Load SQL Architecture

This document describes how elevata transforms metadata into executable SQL for load operations.

---

## ğŸ”§ 1. Overview

The load SQL pipeline turns metadata into **complete SQL statements** suitable for execution on analytical backends.  

Highâ€‘level flow:

```
Metadata â†’ Logical Plan â†’ Expression AST â†’ Dialect Rendering â†’ SQL Load Statement â†’ Execution
```

The system is designed so that:  
- metadata remains backendâ€‘agnostic  
- logical plans describe *what* is required, not *how* it is written  
- dialects encapsulate syntactic differences  
- execution engines are decoupled from SQL generation

---

## ğŸ”§ 2. Logical Plans for Load Operations

elevata represents load operations using SQL primitives:  

- `LogicalSelect` â€“ core building block  
- `LogicalUnion` â€“ multi-source resolution  
- `SubquerySource` â€“ ranking, filtering, preâ€‘aggregation  

Logical plans are intentionally **dialectâ€‘neutral**.

---

## ğŸ”§ 3. Expression AST in Load SQL

Every column expression is represented as an AST node during load generation.  

Supported node types include:  
- `ColumnRef`  
- `Literal`  
- `ExprRef`  
- `ConcatExpr`  
- `ConcatWsExpr`  
- `CoalesceExpr`  
- `WindowFunctionExpr`  
- `Hash256Expr`  

The AST guarantees that:  
- hashing is consistent across dialects  
- CONCAT / COALESCE behave uniformly  
- window functions are structured, not stringâ€‘built  
- SQL remains predictable and comparable

---

## ğŸ”§ 4. Dialect Rendering

After a logical plan is constructed, the selected dialect renders the plan and its AST into concrete SQL.

```
sql = dialect.render_select(plan)
```

Each dialect implements:  
- identifier quoting  
- literal rendering  
- hashing functions  
- CONCAT / CONCAT_WS  
- COALESCE  
- window functions  
- subqueries and unions  

This ensures consistent semantics while using native SQL syntax per backend.

---

## ğŸ”§ 5. Load Runner

The **Load Runner CLI** (`elevata_load`) orchestrates SQL generation and execution.  

It:  
- resolves the active profile and target system  
- reads target dataset metadata  
- constructs the logical plan  
- renders SQL via the active dialect  
- optionally executes SQL in the target warehouse  

The same pipeline is used for SQL preview and execution.

---

## ğŸ”§ 6. Deterministic Generation

The SQL generation pipeline is fully deterministic:  
- stable business-key ordering  
- stable hashing patterns  
- stable helper column naming  
- stable logical plan structure  

This guarantees reproducible SQL and predictable diffs.

---

## ğŸ”§ 7. Mergeâ€‘based Incremental SQL Generation (Rawcore)

This section documents how mergeâ€‘based incremental loads are implemented for Rawcore targets.

### ğŸ§© 7.1 Source Resolution

For targets using `incremental_strategy = "merge"`, the SQL layer resolves the Stage upstream dataset as the merge source:  

- source: `stage.<table> AS s`  
- target: `rawcore.<table> AS t`  

Lineage metadata guarantees compatible natural keys and attribute sets.

### ğŸ§© 7.2 Natural Key Join

Natural key fields define:  
- the merge join condition  
- identification of new vs. existing rows  
- deleteâ€‘detection scope  

If no natural key is defined, SQL generation fails.

### ğŸ§© 7.3 Logical Plan Reuse

All column expressions used in UPDATE and INSERT branches are reused from the logical plan.  

Business logic is defined once and rendered consistently.

### ğŸ§© 7.4 Dialectâ€‘dependent Strategy

Dialects choose between:  
- native `MERGE` statements  
- fallback `UPDATE` + `INSERT ... WHERE NOT EXISTS` patterns  

Both paths reuse the same logical plan expressions.

### ğŸ§© 7.5 Delete Detection

Delete detection is implemented as a separate antiâ€‘join statement that runs before the merge.  

The SQL layer translates incremental scope filters from source lineage into target column expressions.

---

## ğŸ”§ 8. Execution Semantics

Execution semantics are defined by target layer:  

| Layer     | Behaviour |
|----------|-----------|
| `raw`    | Replace when loaded or seeded |
| `stage`  | Always replace (truncate before insert) |
| `rawcore`| Replace only when `mode = full`; incremental runs never truncate |
| `*_hist` | Never truncate; versioned updates only |

Execution always runs **inside the target system**.

---

## ğŸ”§ 9. Execution, Autoâ€‘Provisioning & Warehouse Logging

### ğŸ§© 9.1 Execution Modes

`elevata_load` supports:  

- **Dryâ€‘run**: render SQL without executing it  
- **Execute** (`--execute`): render and execute SQL in the target warehouse

### ğŸ§© 9.2 Autoâ€‘Provisioning

When enabled, execution automatically provisions:  
- target schemas  
- the meta schema  
- the `load_run_log` table  

All DDL is idempotent.

### ğŸ§© 9.3 Warehouseâ€‘level Load Run Log

Each executed load writes a row into `meta.load_run_log`, capturing:  
- batch and load run IDs  
- target dataset and system  
- load mode and flags  
- timestamps and durations  
- execution status and error details  

This enables warehouseâ€‘native observability and auditing.

---

## ğŸ”§ 10. Load Observability & Debugging

Load runs expose structured summaries, batch grouping, and CLIâ€‘level logging to support debugging and monitoring.

---

## ğŸ”§ 11. CLI Usage

The `elevata_load` command supports preview, debugging, batch execution, and warehouse execution.

---

## ğŸ”§ 12. Execute Mode

The `--execute` flag enables direct execution of load SQL in the target warehouse via dialectâ€‘specific execution engines.

---

Â© 2025 elevata Labs â€” Internal Technical Documentation
