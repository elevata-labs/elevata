# elevata Airflow Example

This directory contains an optional Apache Airflow setup demonstrating how elevata datasets  
can be orchestrated using a lineage-driven execution graph.

This example demonstrates how elevata lineage can directly drive orchestration.  
The Airflow DAG is generated from the elevata execution manifest.

This example is provided as a convenience and is **not required** to use elevata.

---

## Quickstart

From the repository root:

```bash
cd examples/airflow
docker compose up --build
```

Then open the Airflow UI:

- http://localhost:8080

---

## Overview

The Airflow DAG is generated from an elevata execution manifest:

```yaml
datasets connected through lineage relationships
```

The manifest is generated by elevata and should not be edited manually.

It contains:

- all target datasets  
- lineage dependencies  
- information required to maximize parallel execution

Airflow uses this information to build a deterministic execution graph.

---

## Workflow

The `elevata_load` DAG works as follows:

1. The DAG checks whether a manifest already exists.  
2. The task `generate_manifest` runs elevata to generate or update the manifest.  
3. The DAG executes dataset loads according to the manifest.  
4. The updated manifest is used on the next DAG parse.

This ensures:

- the DAG is always visible in the Airflow UI  
- execution order is deterministic  
- orchestration reflects elevata lineage

---

## First Run

After starting Airflow:

1. Trigger the DAG `elevata_load` once.  
2. This generates the initial manifest file.  
3. Refresh the DAG view (or wait for scheduler reload).  
4. The full execution graph becomes visible.

---

## Environment Configuration

The Airflow example reads elevata configuration from the repository root `.env` file.

At minimum the following variables should be defined:

ELEVATA_SQL_DIALECT=databricks  
ELEVATA_TARGET_SYSTEM=dbdwh  
ELEVATA_PROFILE=dev

The Airflow example does not provide a target database.  
Users are expected to configure their own target system.

Backend-specific dependencies are installed automatically at container startup
based on `ELEVATA_SQL_DIALECT`.

---

## Configuration

Environment variables:

| Variable | Description |
|---|---|
| `ELEVATA_SQL_DIALECT` | backend adapter selection (e.g. `bigquery`, `databricks`, `duckdb`, `fabric_warehouse`, `mssql`, `postgres`, `snowflake`) |
| `ELEVATA_PROFILE` | elevata profile (e.g. `dev`, `prod`) |
| `ELEVATA_TARGET_SYSTEM` | target system short name |
| `ELEVATA_MANIFEST_PATH` | optional override for manifest location |
| `ELEVATA_CMD` | command used to invoke elevata (default: `python /opt/elevata/core/manage.py`) |

---

## Manifest Location

By default the manifest is written to:

```yaml
core/.artifacts/elevata/manifest_<profile>_<target>.json
```

---

## Dependency Selection (Backend Requirements)

The Airflow example image installs only:

- `requirements/base.txt`

Backend-specific dependencies are installed **at container startup** based on:

- `ELEVATA_SQL_DIALECT`

If `ELEVATA_SQL_DIALECT=databricks`, the container entrypoint installs:

- `requirements/databricks.txt`

To switch the backend, set for example:

```bash
ELEVATA_SQL_DIALECT=duckdb
```

and ensure a matching file exists in:

```bash
requirements/<dialect>.txt
```

To avoid re-installing dependencies on every container start, the entrypoint writes a small  
stamp file after the first successful installation.

---

## Notes

- Source datasets appear in the manifest for lineage completeness but do not create Airflow tasks.  
- Dataset execution is parallelized based on lineage dependencies.  
- Datasets run as soon as all upstream dependencies are completed.  
- The manifest is the single source of truth for execution ordering.

---

## Example Stability Contract

To keep this example easy to adopt and update, the following parts are intended to remain stable:

- **DAG ID**: `elevata_load`  
- **Environment variables**:  
  - `ELEVATA_SQL_DIALECT`  
  - `ELEVATA_PROFILE`  
  - `ELEVATA_TARGET_SYSTEM`  
  - `ELEVATA_MANIFEST_PATH` (optional override)  
  - `ELEVATA_CMD`  
- **Manifest fields used by the DAG**:  
  - `nodes[].id`  
  - `nodes[].type`  
  - `nodes[].deps`  
  - `nodes[].upstream_ids` (or equivalent dependency field)

If the manifest format changes in the future, it should remain backward compatible or be  
versioned explicitly (e.g. `manifest_version`) so orchestration examples can adapt cleanly.

---

## License

Apache Airflow is licensed under the Apache License 2.0.  
It is not bundled with elevata; this example uses official Airflow Docker images.


---

© 2025-2026 elevata Labs — Internal Technical Documentation